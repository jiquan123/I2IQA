# I2IQA
This is the official repo of the paper [PKU-I2IQA: An Image-to-Image Quality
 Assessment Database for AI Generated Images](http://arxiv.org/abs/2311.15556):
  ```
@misc{yuan2023pkui2iqa,
      title={PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI Generated Images}, 
      author={Jiquan Yuan and Xinyan Cao and Changjin Li and Fanyi Yang and Jinlong Lin and Xixin Cao},
      year={2023},
      eprint={2311.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
<hr />

> **Abstract:** *As image generation technology advances, AI-based image generation has been applied in various fields and Artificial Intelligence Generated Content (AIGC) has garnered widespread attention. However, the development of AI-based image generative models also brings new problems and challenges. A significant challenge is that AI-generated images (AIGI) may exhibit unique distortions compared to natural images, and not all generated images meet the requirements of the real world. Therefore, it is of great significance to evaluate AIGIs more comprehensively. Although previous work has established several human perception-based AIGC image quality assessment (AIGCIQA) databases for text-generated images, the AI image generation technology includes scenarios like text-to-image and image-to-image, and assessing only the images generated by text-to-image models is insufficient. To address this issue, we establish a human perception-based image-to-image AIGCIQA database, named PKU-I2IQA. We conduct a well-organized subjective experiment to collect quality labels for AIGIs and then conduct a comprehensive analysis of the PKU-I2IQA database. Furthermore, we propose two benchmark models: NR-AIGCIQA based on the no-reference image quality assessment method and FR-AIGCIQA based on the full-reference image quality assessment method. Finally, leveraging this database, we conduct benchmark experiments and compare the performance of the proposed benchmark models.* 
<hr />

### Sampled images
Different scenes and styles of images sampled from the PKU-I2IQA
database, generated by Midjourney and Stable Diffusion V1.5.

![samples_imgs](https://github.com/jiquan123/I2IQA/blob/main/Pic/1.png)

### NR-AIGCIQA
![NR_imgs](https://github.com/jiquan123/I2IQA/blob/main/Pic/5.png)

### FR-AIGCIQA
![FR_imgs](https://github.com/jiquan123/I2IQA/blob/main/Pic/6.png)

### Pre-trained visual backbone
For feature extraction from input images, we selected several backbone
network models pre-trained on the ImageNet dataset, including:
-  VGG16 [url](https://download.pytorch.org/models/vgg16-397923af.pth)
-  VGG19 [url](https://download.pytorch.org/models/vgg19-dcbb9e9d.pth)
-  ResNet18 [url](https://download.pytorch.org/models/resnet18-f37072fd.pth)
-  ResNet50 [url](https://download.pytorch.org/models/resnet50-0676ba61.pth)
-  InceptionV4 [url](http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth)

### Experimental results
We will continue to provide more experimental results in the following.
- cross-model evaluation experiments
training on images generated by SD and testing on images generated by MJ
![SD-MJ](https://github.com/jiquan123/I2IQA/blob/main/Pic/SD-MJ.png)

training on images generated by MJ and testing on images generated by SD
![MJ-SD](https://github.com/jiquan123/I2IQA/blob/main/Pic/MJ-SD.png)

### Database
The constructed PKU-I2IQA database can be accessed using the links below.
Download PKU-I2IQA database:[[百度网盘](https://pan.baidu.com/s/1Jq6aAW5y3i_p5jgoRWvB8w ) 
(提取码：i2ia)].

### Contact
If you have any question, please contact yuanjiquan@stu.pku.edu.cn


